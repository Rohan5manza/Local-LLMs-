# Local-LLMs-
Projects wherein I run miniaturized Large Language models with custom modifications or enhancements, locally on my CPU
Refer to main.py and ss folder for main content(remaining files were uploaded by mistake.)
Popular LLM alternatives to Chat-GPT, are LLMs such as Llama-2, alpaca, LaMini-LM, etc; those that can be run locally on my computer, both on CPU or GPU.

My project aim: to learn more about LLMs, and to build a metric calculating tool to monitor its performance and resource usage: tokens/second generated, pipelines used,GPU consumption, etc.

Part 1: Alpaca-Lora, used for fine-tuning 7B parameter Llama model. I wrote code,to train it on Bitcoin tweets dataset for sentiment analysis, by refering from an online guide.
Project aborted due to dependencies issues which cannot be solved.

Part 2: LaMini-LM. Successfully completed project.
Used text-generation-webUI called oobabooga , to create an interface to interact with the LLM. Refered to multiple online sources to complete the project.

Definitely explore oobabooga more, amazing tool can download many different types of LLMs or HuggingFace models, ad play around with parameters, train or customize models,etc.
